{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Transformers - Autosummarization Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this notebook is based on chapter 6 **Summarization** of the book **Natural Language Processing with Tranformers** and can be found [here](https://nbviewer.org/github/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB4PkWm8-pfn"
   },
   "source": [
    "## Imports, Inits, and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:23:57.281593Z",
     "start_time": "2022-07-07T00:23:45.542211Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, pickle, sys, warnings, tqdm, time, torch\n",
    "warnings.filterwarnings(action='ignore')\n",
    "sys.path.insert(0, '../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoTokenizer,\n",
    "                          AutoModelForQuestionAnswering)\n",
    "from transformers import DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from transformers.data.processors.squad import SquadV1Processor\n",
    "from datasets import load_dataset, load_metric\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:23:57.362529Z",
     "start_time": "2022-07-07T00:23:57.284243Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text='article', column_summary='abstract'):\n",
    "  summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "  metric.add_batch(predictions=summaries, references=dataset[column_summary])    \n",
    "  score = metric.compute()\n",
    "  return score\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "  \"\"\"\n",
    "  Yield successive batch-sized chunks from list_of_elements.\n",
    "  \"\"\"\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=8, device=device, column_text='article',\n",
    "                               column_summary='abstract'):\n",
    "  article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "  target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "  for article_batch, target_batch in tqdm_notebook(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "    inputs = tokenizer(article_batch, max_length=1024,  truncation=True, padding='max_length', return_tensors='pt')\n",
    "    summaries = model.generate(input_ids=inputs['input_ids'].to(device),\n",
    "                               attention_mask=inputs['attention_mask'].to(device),\n",
    "                               length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "    decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                          clean_up_tokenization_spaces=True)\n",
    "                         for s in summaries]\n",
    "    decoded_summaries = [d.replace('<n>', ' ') for d in decoded_summaries]\n",
    "    metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "  score = metric.compute()\n",
    "  return score\n",
    "\n",
    "def convert_examples_to_features(example_batch):\n",
    "  input_encodings = tokenizer(example_batch['dialogue'], max_length=1024, truncation=True)\n",
    "\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    target_encodings = tokenizer(example_batch['summary'], max_length=128, truncation=True)\n",
    "\n",
    "  return {'input_ids': input_encodings['input_ids'],\n",
    "          'attention_mask': input_encodings['attention_mask'],\n",
    "          'labels': target_encodings['input_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace's Summarization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using for this task is the Pubmed Summarization dataset which consists of 119,924 pairs of articles and their corresponding abstracts.\n",
    "\n",
    "This dataset can be found in the Hugging Face hub [here](https://huggingface.co/datasets/ccdv/pubmed-summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:23:58.327747Z",
     "start_time": "2022-07-07T00:23:57.364034Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /net/kdinxidk03/opt/NFS/huggingface_cache/modules/datasets_modules/datasets/ccdv--pubmed-summarization/f9a2a592892a29ff6b5579891a7d5fcc3e15642540af26d1f6ac99086dc9fecd (last modified on Mon Jul  4 16:15:38 2022) since it couldn't be found locally at ccdv/pubmed-summarization., or remotely on the Hugging Face Hub.\n",
      "No config specified, defaulting to: pubmed-summarization/section\n",
      "Reusing dataset pubmed-summarization (/net/kdinxidk03/opt/NFS/huggingface_cache/datasets/ccdv___pubmed-summarization/section/1.0.0/f9a2a592892a29ff6b5579891a7d5fcc3e15642540af26d1f6ac99086dc9fecd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4099060ade34280a49c98358f98e3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'abstract']\n",
      "Article (excerpt of 500 characters, total length: 7419):\n",
      "tardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face . \n",
      " td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . \n",
      " . the low risk of td for atypical antipsychotics is thought to result from their weak affinity for \n",
      "\n",
      "Summary (length: 1009):\n",
      "tardive dystonia ( td ) is a serious side effect of antipsychotic medications , more with typical antipsychotics , that is potentially irreversible in affected patients . \n",
      " studies show that newer atypical antipsychotics have a lower risk of td . as a result , many clinicians may have developed a false sense of security when prescribing these medications . \n",
      " we report a case of 20-year - old male with hyperthymic temperament and borderline intellectual functioning , who developed severe td after low dose short duration exposure to atypical antipsychotic risperidone and then olanzapine . \n",
      " the goal of this paper is to alert the reader to be judicious and cautious before using casual low dose second generation antipsychotics in patient with no core psychotic features , hyperthymic temperament , or borderline intellectual functioning suggestive of organic brain damage , who are more prone to develop adverse effects such as td and monitor the onset of td in patients taking atypical antipsychotics .\n"
     ]
    }
   ],
   "source": [
    "# art_idx = 40767\n",
    "art_idx = 2\n",
    "# dataset = load_dataset('cnn_dailymail', version='3.0.0')\n",
    "dataset = load_dataset('ccdv/pubmed-summarization')\n",
    "print(f\"Features: {dataset['train'].column_names}\")\n",
    "\n",
    "sample_text = dataset['train'][art_idx]\n",
    "print(f\"Article (excerpt of 500 characters, total length: {len(sample_text['article'])}):\")\n",
    "print(sample_text['article'][:500])\n",
    "print(f\"\\nSummary (length: {len(sample_text['abstract'])}):\")\n",
    "print(sample_text['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the articles' length to 2000 characters to have the same input to all the models and due to memory restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:23:58.418633Z",
     "start_time": "2022-07-07T00:23:58.331021Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][art_idx]['article'][:2000]\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Summaries using Different Models Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:23:58.493721Z",
     "start_time": "2022-07-07T00:23:58.420433Z"
    }
   },
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "  return '\\n'.join(sent_tokenize(text)[:3])\n",
    "\n",
    "summaries['baseline'] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding `TL;DR:` at the end of the article prompts the GPT-2 model to generate a summary instead to generating free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:24:53.657030Z",
     "start_time": "2022-07-07T00:23:58.495679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 17:54:15.260041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-07 17:54:15.260494: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-07 17:54:15.261223: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-generation', model='gpt2-xl')\n",
    "gpt2_query = sample_text + '\\nTL;DR:\\n' \n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries['gpt2'] = '\\n'.join(sent_tokenize(pipe_out[0]['generated_text'][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 transformer is a universal trasnformer architecture by formulating all tasks as text-to-text tasks. T5 checkpoints are trained ona mixture of unsupervised data (to resconstruct masked words) and supervised data for several tasks including summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:25:22.359885Z",
     "start_time": "2022-07-07T00:24:53.659533Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model='t5-large')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['t5'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART also uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs. It combines pretraining schemes of BERT and GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:25:32.639373Z",
     "start_time": "2022-07-07T00:25:22.363475Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['bart'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEAGSUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEAGSUS is also an encoder-decoder architecture that is based on the premise that the closer the pretraining objective is to the downstream task, the more effectifve it is. In a very large corpus, sentences containing most of the content in their surrounding paragraphs can be reconstructed to obtain a SOTA model for text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:26:07.980435Z",
     "start_time": "2022-07-07T00:25:32.643933Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model='google/pegasus-pubmed')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['pegasus'] = pipe_out[0]['summary_text'].replace(' .<n>', '.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Generated Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:26:08.446969Z",
     "start_time": "2022-07-07T00:26:07.984684Z"
    }
   },
   "outputs": [],
   "source": [
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:26:08.512937Z",
     "start_time": "2022-07-07T00:26:08.448584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGROUND TRUTH\u001b[0m\n",
      "\u001b[32mtardive dystonia ( td ) is a serious side effect of antipsychotic medications , more with typical antipsychotics , that is potentially irreversible in affected patients . \n",
      " studies show that newer atypical antipsychotics have a lower risk of td . as a result , many clinicians may have developed a false sense of security when prescribing these medications . \n",
      " we report a case of 20-year - old male with hyperthymic temperament and borderline intellectual functioning , who developed severe td after low dose short duration exposure to atypical antipsychotic risperidone and then olanzapine . \n",
      " the goal of this paper is to alert the reader to be judicious and cautious before using casual low dose second generation antipsychotics in patient with no core psychotic features , hyperthymic temperament , or borderline intellectual functioning suggestive of organic brain damage , who are more prone to develop adverse effects such as td and monitor the onset of td in patients taking atypical antipsychotics .\u001b[0m\n",
      "\n",
      "\u001b[31mBASELINE\u001b[0m\n",
      "\u001b[34mtardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face .\n",
      "td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . \n",
      " . the low risk of td for atypical antipsychotics is thought to result from their weak affinity for dopamine receptors .\n",
      "compared with typical , \n",
      " atypical antipsychotic agents have a greater affinity for serotonin 5-ht2a than dopamine d2 receptors , with a low propensity to induce td .\u001b[0m\n",
      "\n",
      "\u001b[31mGPT2\u001b[0m\n",
      "\u001b[34mAntipsychotics are associated with an increased risk of dystonic syndrome when used longer term, most common outcome of short exposure (e.g., 2 months) is extrapyramidal syndrome.\n",
      "A recent uncontrolled multicentric study suggests that olanzapine might be a better alternative than risperidone 2 mg olanzapine is less prone to cause extrap\u001b[0m\n",
      "\n",
      "\u001b[31mT5\u001b[0m\n",
      "\u001b[34mtardive dystonia (td) is a rarer side effect after longer exposure to antipsychotics .\n",
      "it is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group .\n",
      "may affect the limbs , trunk , neck , or face .\n",
      "td has been shown to develop in about 3% of patients who have had long - term exposure .\u001b[0m\n",
      "\n",
      "\u001b[31mBART\u001b[0m\n",
      "\u001b[34m tardive dystonia (td) is a rarer side effect after longer exposure to antipsychotics.\n",
      "It is characterized by local or general, sustained, involuntary contraction of a muscle or muscle group.\n",
      "It has been shown to develop in about 3% of patients who have had long - term exposure to  antipsychotic drugs.\u001b[0m\n",
      "\n",
      "\u001b[31mPEGASUS\u001b[0m\n",
      "\u001b[34mtardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face . td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . <n> the low risk of td for atypical antipsychotics is thought to result from their weak affinity for dopamine receptors . compared with typical , atypical antipsychotic agents have a greater affinity for serotonin 5-ht2a than dopamine d2 receptors , with a low propensity to induce td . among this olanzapine is thought to have preferential action at mesolimbic over nigrostriatal dopaminergic pathways and is , therefore , associated with a very low incidence of extrapyramidal symptom ( eps ) . <n> furthermore , a retrospective analysis of controlled multicentric trials suggested that olanzapine also improves preexisting symptoms of tardive movements .\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(colored('GROUND TRUTH', 'red'))\n",
    "print(colored(dataset['train'][art_idx]['abstract'], 'green'))\n",
    "print('')\n",
    "\n",
    "for model_name in summaries:\n",
    "  print(colored(model_name.upper(), 'red'))\n",
    "  print(colored(summaries[model_name], 'blue'))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating using ROGUE Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROUGE score was developed for applications like summarization where high recall is more important than precision. ROUGE is calculated based on how many `n`-grams in the reference text also occur in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:26:12.318436Z",
     "start_time": "2022-07-07T00:26:08.514719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /net/kdinxidk03/opt/NFS/huggingface_cache/modules/datasets_modules/metrics/rouge/0ffdb60f436bdb8884d5e4d608d53dbe108e82dac4f494a66f80ef3f647c104f (last modified on Tue Jul  5 12:28:09 2022) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n",
      "Loading cached shuffled indices for dataset at /net/kdinxidk03/opt/NFS/huggingface_cache/datasets/ccdv___pubmed-summarization/section/1.0.0/f9a2a592892a29ff6b5579891a7d5fcc3e15642540af26d1f6ac99086dc9fecd/cache-6df034ac805cbe09.arrow\n"
     ]
    }
   ],
   "source": [
    "rouge_metric = load_metric('rouge', chace_dir=None)\n",
    "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "\n",
    "test_sampled = dataset['test'].shuffle(seed=42).select(range(250))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "rogue_scores = pd.DataFrame.from_dict(rouge_dict, orient='index', columns=['baseline']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:29:18.307313Z",
     "start_time": "2022-07-07T00:26:12.320448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879cec52030549bbb2adc937faff8300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.090744</td>\n",
       "      <td>0.168766</td>\n",
       "      <td>0.244628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.350126</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>0.226754</td>\n",
       "      <td>0.296896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.270288  0.090744  0.168766   0.244628\n",
       "pegasus   0.350126  0.154301  0.226754   0.296896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = \"google/pegasus-pubmed\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=4)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "rogue_scores = rogue_scores.append(pd.DataFrame(rouge_dict, index=[\"pegasus\"]))\n",
    "rogue_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Transformers - Question Answering/ Machine Reading Comprehension Use Case\n",
    "\n",
    "The second and final part of this notebook is adapted from the HuggingFace's QA pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace's QA pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dev dataset using HuggingFace data processors\n",
    "\n",
    "The dev dataset we are using for this task is the SQuAD-1.1 MRC dataset which consists of 10,570 question-answer pairs and 48 unique contexts.\n",
    "\n",
    "This dataset can be found in the Hugging Face hub [here](https://huggingface.co/datasets/squad).\n",
    "\n",
    "Hugging Face provides the [Processors](https://huggingface.co/transformers/main_classes/processors.html) library for facilitating basic processing tasks with some canonical NLP datasets. The processors can be used for loading datasets and converting their examples to features for direct use in the model. We'll be using the [SQuAD processors](https://huggingface.co/transformers/main_classes/processors.html#squad). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 48/48 [00:02<00:00, 16.81it/s]\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/net/kdinxidk03/opt/NFS/collab_dir/SIGIR2022/\"\n",
    "processor = SquadV1Processor()\n",
    "examples = processor.get_dev_examples(path_data, filename=\"squad/test_squad.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example sample in the SQuAD-1.1 development set:  \n",
      "\n",
      "Question:  What day was the Super Bowl played on? \n",
      "\n",
      "Context:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. \n",
      "\n",
      "Answer:  February 7, 2016\n"
     ]
    }
   ],
   "source": [
    "print('An example sample in the SQuAD-1.1 development set: ',\n",
    "      '\\n\\nQuestion: ', examples[10].__dict__['question_text'],\n",
    "      '\\n\\nContext: ', examples[10].__dict__['context_text'],\n",
    "      '\\n\\nAnswer: ', examples[10].__dict__['answers'][0]['text'],\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_example(qid):    \n",
    "  idx = qid_to_example_index[qid]\n",
    "  q = examples[idx].question_text\n",
    "  c = examples[idx].context_text\n",
    "  a = [answer['text'] for answer in examples[idx].answers]\n",
    "\n",
    "  print(f'Example {idx} of {len(examples)}\\n---------------------')\n",
    "  print(f\"Q: {q}\\n\")\n",
    "  print(\"Context:\")\n",
    "  print(c)\n",
    "  print(f\"\\nTrue Answers:\\n{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 120 of 10570\n",
      "---------------------\n",
      "Q: What venue in Miami was a candidate for the site of Super Bowl 50?\n",
      "\n",
      "Context:\n",
      "The league eventually narrowed the bids to three sites: New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.\n",
      "\n",
      "True Answers:\n",
      "['Sun Life Stadium', 'Sun Life Stadium', 'Sun Life Stadium']\n"
     ]
    }
   ],
   "source": [
    "qid_to_example_index = {example.qas_id: i for i, example in enumerate(examples)}\n",
    "answer_qids = list(qid_to_example_index.keys())\n",
    "display_example(answer_qids[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a transformer model fine-tuned on SQuAD-1.1 for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"csarron/bert-base-uncased-squad-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction and evaluate the prediction using EM & F1 metrics\n",
    "\n",
    "* Metrics for QA:\n",
    "\n",
    "1. Exact Match (EM): For each question+answer pair, if the _characters_ of the model's prediction exactly match the characters of (one of) the True Answer(s), EM = 1, otherwise EM = 0. This is a strict all-or-nothing metric; being off by a single character results in a score of 0.\n",
    "\n",
    "2. F1: F1 score is a common metric for classification problems, and widely used in QA. It is appropriate when we care equally about precision and recall. In this case, it's computed over the individual _words_ in the prediction against those in the True Answer. The number of shared words between the prediction and the truth is the basis of the F1 score: precision is the ratio of the number of shared words to the total number of words in the _prediction_, and recall is the ratio of the number of shared words to the total number of words in the _ground truth_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(qid):\n",
    "    # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n",
    "    question = examples[qid_to_example_index[qid]].question_text\n",
    "    context = examples[qid_to_example_index[qid]].context_text\n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(outputs[1]) + 1 \n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example - \n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "        \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Who had the best record in the NFC?\n",
      "\n",
      "Prediction: carolina panthers\n",
      "\n",
      "True Answers: ['Carolina Panthers', 'the Panthers', 'Carolina']\n",
      "\n",
      "Performance Scores: EM: 1 \t F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "prediction = get_prediction(answer_qids[idx])\n",
    "example = examples[qid_to_example_index[answer_qids[idx]]]\n",
    "gold_answers = get_gold_answers(example)\n",
    "\n",
    "em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
    "\n",
    "print(f\"\\nQuestion: {example.question_text}\")\n",
    "print(f\"\\nPrediction: {prediction}\")\n",
    "print(f\"\\nTrue Answers: {gold_answers}\")\n",
    "print(f\"\\nPerformance Scores: EM: {em_score} \\t F1: {f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqU6fryZc2CDjTChc1LC5b",
   "include_colab_link": true,
   "name": "SIGIR 2022 Efficient Transformers for IR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.875px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
