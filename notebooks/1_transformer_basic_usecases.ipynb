{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this notebook is based on chapter 6 **Summarization** of the book **Natural Language Processing with Tranformers** and can be found [here](https://nbviewer.org/github/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB4PkWm8-pfn"
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:19.839041Z",
     "start_time": "2022-07-09T02:12:12.681741Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, pickle, sys, warnings, tqdm, time, torch\n",
    "warnings.filterwarnings(action='ignore')\n",
    "sys.path.insert(0, '../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from termcolor import colored\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoTokenizer,\n",
    "                          AutoModelForQuestionAnswering)\n",
    "from transformers import DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from transformers.data.processors.squad import SquadV1Processor\n",
    "from datasets import load_dataset, load_metric\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string, re\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:19.908312Z",
     "start_time": "2022-07-09T02:12:19.841252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text='article', column_summary='abstract'):\n",
    "  summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "  metric.add_batch(predictions=summaries, references=dataset[column_summary])    \n",
    "  score = metric.compute()\n",
    "  return score\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "  \"\"\"\n",
    "  Yield successive batch-sized chunks from list_of_elements.\n",
    "  \"\"\"\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=8, device=device, column_text='article',\n",
    "                               column_summary='abstract'):\n",
    "  article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "  target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "  for article_batch, target_batch in tqdm_notebook(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "    inputs = tokenizer(article_batch, max_length=1024,  truncation=True, padding='max_length', return_tensors='pt')\n",
    "    summaries = model.generate(input_ids=inputs['input_ids'].to(device),\n",
    "                               attention_mask=inputs['attention_mask'].to(device),\n",
    "                               length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "    decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                          clean_up_tokenization_spaces=True)\n",
    "                         for s in summaries]\n",
    "    decoded_summaries = [d.replace('<n>', ' ') for d in decoded_summaries]\n",
    "    metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "  score = metric.compute()\n",
    "  return score\n",
    "\n",
    "def convert_examples_to_features(example_batch):\n",
    "  input_encodings = tokenizer(example_batch['dialogue'], max_length=1024, truncation=True)\n",
    "\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    target_encodings = tokenizer(example_batch['summary'], max_length=128, truncation=True)\n",
    "\n",
    "  return {'input_ids': input_encodings['input_ids'],\n",
    "          'attention_mask': input_encodings['attention_mask'],\n",
    "          'labels': target_encodings['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:19.973787Z",
     "start_time": "2022-07-09T02:12:19.910148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_example(qid):    \n",
    "  idx = qid_to_example_index[qid]\n",
    "  q = examples[idx].question_text\n",
    "  c = examples[idx].context_text\n",
    "  a = [answer['text'] for answer in examples[idx].answers]\n",
    "\n",
    "  print(f'Example {idx} of {len(examples)}\\n---------------------')\n",
    "  print(f\"Q: {q}\\n\")\n",
    "  print(\"Context:\")\n",
    "  print(c)\n",
    "  print(f\"\\nTrue Answers:\\n{a}\")\n",
    "  \n",
    "def get_prediction(qid):\n",
    "  # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n",
    "  question = examples[qid_to_example_index[qid]].question_text\n",
    "  context = examples[qid_to_example_index[qid]].context_text\n",
    "\n",
    "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "\n",
    "  outputs = model(**inputs)\n",
    "  answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
    "  answer_end = torch.argmax(outputs[1]) + 1 \n",
    "\n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "  return answer\n",
    "  \n",
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    return re.sub(regex, \" \", text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "  return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "  pred_tokens = normalize_text(prediction).split()\n",
    "  truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "    return int(pred_tokens == truth_tokens)\n",
    "\n",
    "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "  # if there are no common tokens then f1 = 0\n",
    "  if len(common_tokens) == 0:\n",
    "    return 0\n",
    "\n",
    "  prec = len(common_tokens) / len(pred_tokens)\n",
    "  rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "  return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "    \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace's Summarization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using for this task is the Pubmed Summarization dataset which consists of 119,924 pairs of articles and their corresponding abstracts.\n",
    "\n",
    "This dataset can be found in the Hugging Face hub [here](https://huggingface.co/datasets/ccdv/pubmed-summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:26.063096Z",
     "start_time": "2022-07-09T02:12:25.036650Z"
    }
   },
   "outputs": [],
   "source": [
    "art_idx = 2\n",
    "dataset = load_dataset('ccdv/pubmed-summarization')\n",
    "# print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:32.801360Z",
     "start_time": "2022-07-09T02:12:32.685369Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (excerpt of 500 characters, total length: 7419):\n",
      "tardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face . \n",
      " td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . \n",
      " . the low risk of td for atypical antipsychotics is thought to result from their weak affinity for \n",
      "\n",
      "Summary (length: 1009):\n",
      "tardive dystonia ( td ) is a serious side effect of antipsychotic medications , more with typical antipsychotics , that is potentially irreversible in affected patients . \n",
      " studies show that newer atypical antipsychotics have a lower risk of td . as a result , many clinicians may have developed a false sense of security when prescribing these medications . \n",
      " we report a case of 20-year - old male with hyperthymic temperament and borderline intellectual functioning , who developed severe td after low dose short duration exposure to atypical antipsychotic risperidone and then olanzapine . \n",
      " the goal of this paper is to alert the reader to be judicious and cautious before using casual low dose second generation antipsychotics in patient with no core psychotic features , hyperthymic temperament , or borderline intellectual functioning suggestive of organic brain damage , who are more prone to develop adverse effects such as td and monitor the onset of td in patients taking atypical antipsychotics .\n"
     ]
    }
   ],
   "source": [
    "sample_text = dataset['train'][art_idx]\n",
    "print(f\"Article (excerpt of 500 characters, total length: {len(sample_text['article'])}):\")\n",
    "print(sample_text['article'][:500])\n",
    "print(f\"\\nSummary (length: {len(sample_text['abstract'])}):\")\n",
    "print(sample_text['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the articles' length to 2000 characters to have the same input to all the models and due to memory restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:35.923514Z",
     "start_time": "2022-07-09T02:12:35.790620Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][art_idx]['article'][:2000]\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Summaries using Different Models Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primitive Summarization - Just take first 3 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:12:37.554097Z",
     "start_time": "2022-07-09T02:12:37.429154Z"
    }
   },
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "  return '\\n'.join(sent_tokenize(text)[:3])\n",
    "\n",
    "summaries['baseline'] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization with GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding `TL;DR:` at the end of the article prompts the GPT-2 model to generate a summary instead to generating free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:13:30.395253Z",
     "start_time": "2022-07-09T02:12:38.711478Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('text-generation', model='gpt2-xl')\n",
    "gpt2_query = sample_text + '\\nTL;DR:\\n' \n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries['gpt2'] = '\\n'.join(sent_tokenize(pipe_out[0]['generated_text'][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 transformer is a universal trasnformer architecture by formulating all tasks as text-to-text tasks. T5 checkpoints are trained ona mixture of unsupervised data (to resconstruct masked words) and supervised data for several tasks including summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:13:58.023834Z",
     "start_time": "2022-07-09T02:13:30.400792Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model='t5-large')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['t5'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART also uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs. It combines pretraining schemes of BERT and GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:14:08.166853Z",
     "start_time": "2022-07-09T02:13:58.030708Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['bart'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEAGSUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEAGSUS is also an encoder-decoder architecture that is based on the premise that the closer the pretraining objective is to the downstream task, the more effectifve it is. In a very large corpus, sentences containing most of the content in their surrounding paragraphs can be reconstructed to obtain a SOTA model for text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:14:42.927137Z",
     "start_time": "2022-07-09T02:14:08.170410Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model='google/pegasus-pubmed')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries['pegasus'] = pipe_out[0]['summary_text'].replace(' .<n>', '.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Generated Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:14:43.920447Z",
     "start_time": "2022-07-09T02:14:42.930012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mOriginal\u001b[0m\n",
      "\u001b[32mtardive dystonia ( td ) is a serious side effect of antipsychotic medications , more with typical antipsychotics , that is potentially irreversible in affected patients . \n",
      " studies show that newer atypical antipsychotics have a lower risk of td . as a result , many clinicians may have developed a false sense of security when prescribing these medications . \n",
      " we report a case of 20-year - old male with hyperthymic temperament and borderline intellectual functioning , who developed severe td after low dose short duration exposure to atypical antipsychotic risperidone and then olanzapine . \n",
      " the goal of this paper is to alert the reader to be judicious and cautious before using casual low dose second generation antipsychotics in patient with no core psychotic features , hyperthymic temperament , or borderline intellectual functioning suggestive of organic brain damage , who are more prone to develop adverse effects such as td and monitor the onset of td in patients taking atypical antipsychotics .\u001b[0m\n",
      "\n",
      "\u001b[31mBASELINE\u001b[0m\n",
      "\u001b[34mtardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face .\n",
      "td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . \n",
      " . the low risk of td for atypical antipsychotics is thought to result from their weak affinity for dopamine receptors .\n",
      "compared with typical , \n",
      " atypical antipsychotic agents have a greater affinity for serotonin 5-ht2a than dopamine d2 receptors , with a low propensity to induce td .\u001b[0m\n",
      "\n",
      "\u001b[31mGPT2\u001b[0m\n",
      "\u001b[34mAntipsychotics are associated with an increased risk of dystonic syndrome when used longer term, most common outcome of short exposure (e.g., 2 months) is extrapyramidal syndrome.\n",
      "A recent uncontrolled multicentric study suggests that olanzapine might be a better alternative than risperidone 2 mg olanzapine is less prone to cause extrap\u001b[0m\n",
      "\n",
      "\u001b[31mT5\u001b[0m\n",
      "\u001b[34mtardive dystonia (td) is a rarer side effect after longer exposure to antipsychotics .\n",
      "it is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group .\n",
      "may affect the limbs , trunk , neck , or face .\n",
      "td has been shown to develop in about 3% of patients who have had long - term exposure .\u001b[0m\n",
      "\n",
      "\u001b[31mBART\u001b[0m\n",
      "\u001b[34m tardive dystonia (td) is a rarer side effect after longer exposure to antipsychotics.\n",
      "It is characterized by local or general, sustained, involuntary contraction of a muscle or muscle group.\n",
      "It has been shown to develop in about 3% of patients who have had long - term exposure to  antipsychotic drugs.\u001b[0m\n",
      "\n",
      "\u001b[31mPEGASUS\u001b[0m\n",
      "\u001b[34mtardive dystonia ( td ) , a rarer side effect after longer exposure to antipsychotics , is characterized by local or general , sustained , involuntary contraction of a muscle or muscle group , with twisting movements , generally slow , which may affect the limbs , trunk , neck , or face . td has been shown to develop in about 3% of patients who have had long - term exposure to antipsychotics . <n> the low risk of td for atypical antipsychotics is thought to result from their weak affinity for dopamine receptors . compared with typical , atypical antipsychotic agents have a greater affinity for serotonin 5-ht2a than dopamine d2 receptors , with a low propensity to induce td . among this olanzapine is thought to have preferential action at mesolimbic over nigrostriatal dopaminergic pathways and is , therefore , associated with a very low incidence of extrapyramidal symptom ( eps ) . <n> furthermore , a retrospective analysis of controlled multicentric trials suggested that olanzapine also improves preexisting symptoms of tardive movements .\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(colored('Original', 'red'))\n",
    "print(colored(dataset['train'][art_idx]['abstract'], 'green'))\n",
    "print('')\n",
    "\n",
    "for model_name in summaries:\n",
    "  print(colored(model_name.upper(), 'red'))\n",
    "  print(colored(summaries[model_name], 'blue'))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating using ROGUE Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROUGE score was developed for applications like summarization where high recall is more important than precision. ROUGE is calculated based on how many `n`-grams in the reference text also occur in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:18:47.417442Z",
     "start_time": "2022-07-09T02:15:37.382649Z"
    }
   },
   "outputs": [],
   "source": [
    "rouge_metric = load_metric('rouge', chace_dir=None)\n",
    "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "\n",
    "test_sampled = dataset['test'].shuffle(seed=42).select(range(250))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "rogue_scores = pd.DataFrame.from_dict(rouge_dict, orient='index', columns=['baseline']).T\n",
    "\n",
    "model_ckpt = \"google/pegasus-pubmed\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=4)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "rogue_scores = rogue_scores.append(pd.DataFrame(rouge_dict, index=[\"pegasus\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:18:48.143809Z",
     "start_time": "2022-07-09T02:18:47.420441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.090744</td>\n",
       "      <td>0.168766</td>\n",
       "      <td>0.244628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.350126</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>0.226754</td>\n",
       "      <td>0.296896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.270288  0.090744  0.168766   0.244628\n",
       "pegasus   0.350126  0.154301  0.226754   0.296896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rogue_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace's QA pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset using HuggingFace data processors\n",
    "\n",
    "The test dataset we are using for this task is the SQuAD-1.1 MRC dataset which consists of 10,570 question-answer pairs and 48 unique contexts.\n",
    "\n",
    "[Stanford Question Answering Dataset (SQuAD)](https://arxiv.org/abs/1606.05250) is the first large-scale extractive MRC dataset. It was built by crowd-workers using a set of Wikipedia articles where the answer to each question is an extracted slice from the corresponding text passage.\n",
    "\n",
    "This dataset can be downloaded from the Hugging Face hub [here](https://huggingface.co/datasets/squad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:19:26.067595Z",
     "start_time": "2022-07-09T02:19:22.527450Z"
    }
   },
   "outputs": [],
   "source": [
    "path_data = \"/net/kdinxidk03/opt/NFS/collab_dir/SIGIR2022/\"\n",
    "processor = SquadV1Processor()\n",
    "examples = processor.get_dev_examples(path_data, filename=\"squad/test_squad.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:19:26.132294Z",
     "start_time": "2022-07-09T02:19:26.069631Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example sample in the SQuAD-1.1 development set:  \n",
      "\n",
      "Question:  What day was the Super Bowl played on? \n",
      "\n",
      "Context:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. \n",
      "\n",
      "Answer:  February 7, 2016\n"
     ]
    }
   ],
   "source": [
    "print('An example sample in the SQuAD-1.1 development set: ',\n",
    "      '\\n\\nQuestion: ', examples[10].__dict__['question_text'],\n",
    "      '\\n\\nContext: ', examples[10].__dict__['context_text'],\n",
    "      '\\n\\nAnswer: ', examples[10].__dict__['answers'][0]['text'],\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:19:26.199382Z",
     "start_time": "2022-07-09T02:19:26.134172Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qid_to_example_index = {example.qas_id: i for i, example in enumerate(examples)}\n",
    "answer_qids = list(qid_to_example_index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a transformer model fine-tuned on SQuAD-1.1 for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:19:37.484079Z",
     "start_time": "2022-07-09T02:19:34.136912Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"csarron/bert-base-uncased-squad-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction and evaluate the prediction using EM & F1 metrics\n",
    "\n",
    "* Metrics for QA:\n",
    "\n",
    "1. Exact Match (EM): For each question+answer pair, if the _characters_ of the model's prediction exactly match the characters of (one of) the True Answer(s), EM = 1, otherwise EM = 0. This is a strict all-or-nothing metric; being off by a single character results in a score of 0.\n",
    "\n",
    "2. F1: F1 score is a common metric for classification problems, and widely used in QA. It is appropriate when we care equally about precision and recall. In this case, it's computed over the individual _words_ in the prediction against those in the True Answer. The number of shared words between the prediction and the truth is the basis of the F1 score: precision is the ratio of the number of shared words to the total number of words in the _prediction_, and recall is the ratio of the number of shared words to the total number of words in the _ground truth_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:19:37.711303Z",
     "start_time": "2022-07-09T02:19:37.486688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Who had the best record in the NFC?\n",
      "\n",
      "Context: Despite waiving longtime running back DeAngelo Williams and losing top wide receiver Kelvin Benjamin to a torn ACL in the preseason, the Carolina Panthers had their best regular season in franchise history, becoming the seventh team to win at least 15 regular season games since the league expanded to a 16-game schedule in 1978. Carolina started the season 14–0, not only setting franchise records for the best start and the longest single-season winning streak, but also posting the best start to a season by an NFC team in NFL history, breaking the 13–0 record previously shared with the 2009 New Orleans Saints and the 2011 Green Bay Packers. With their NFC-best 15–1 regular season record, the Panthers clinched home-field advantage throughout the NFC playoffs for the first time in franchise history. Ten players were selected to the Pro Bowl (the most in franchise history) along with eight All-Pro selections.\n",
      "\n",
      "Prediction: carolina panthers\n",
      "\n",
      "True Answers: ['Carolina Panthers', 'the Panthers', 'Carolina']\n"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "prediction = get_prediction(answer_qids[idx])\n",
    "example = examples[qid_to_example_index[answer_qids[idx]]]\n",
    "gold_answers = get_gold_answers(example)\n",
    "\n",
    "em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
    "\n",
    "print(f\"\\nQuestion: {example.question_text}\")\n",
    "print(f\"\\nContext: {example.context_text}\")\n",
    "print(f\"\\nPrediction: {prediction}\")\n",
    "print(f\"\\nTrue Answers: {gold_answers}\")\n",
    "# print(f\"\\nPerformance Scores: EM: {em_score} \\t F1: {f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqU6fryZc2CDjTChc1LC5b",
   "include_colab_link": true,
   "name": "SIGIR 2022 Efficient Transformers for IR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.875px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
