{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d8b918",
   "metadata": {},
   "source": [
    "# Cross-Lingual Semantic-Similarity Search Engine Use Case\n",
    "\n",
    "This notebook has been adapted from [this paper](https://aclanthology.org/2020.acl-demos.12/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3959b55",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc27e732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:17.826856Z",
     "start_time": "2022-07-07T00:33:09.264906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 20:33:10.917902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /net/kdinxidk03/opt/NFS/su0/anaconda3/lib/\n",
      "2022-07-06 20:33:10.917935: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#@title Setup common imports and functions\n",
    "import bokeh\n",
    "import bokeh.models\n",
    "import bokeh.plotting\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_text import SentencepieceTokenizer\n",
    "import sklearn.metrics.pairwise\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import sklearn\n",
    "\n",
    "from simpleneighbors import SimpleNeighbors\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8559a",
   "metadata": {},
   "source": [
    "## Application of a pre-trained transformer model in document retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1a422",
   "metadata": {},
   "source": [
    "### Load Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3104d",
   "metadata": {},
   "source": [
    "We load `xlm-mlm-100-1280` transformer which is language model trained for masked token prediction task on a dataset with 100 languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed0cca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:24.618761Z",
     "start_time": "2022-07-07T00:33:17.829425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /net/kdinxidk03/opt/NFS/sentence_transformers_cache/xlm-mlm-100-1280. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /net/kdinxidk03/opt/NFS/sentence_transformers_cache/xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('xlm-mlm-100-1280')\n",
    "\n",
    "def embed_text(input):\n",
    "  return model.encode(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22de5d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed264f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:27.678764Z",
     "start_time": "2022-07-07T00:33:24.620482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: natural language understanding\n",
      "Sentence 2: comprensión del lenguaje natural\n",
      "Similarity score: 0.7081338167190552\n",
      "\n",
      "Sentence: I like Javascript because I can build web applications\n",
      "Top 2 most similar sentences in corpus:\n",
      "I like Python because I can build AI applications (Score: 0.8240)\n",
      "Me gusta Python porque puedo hacer análisis de datos (Score: 0.6684)\n"
     ]
    }
   ],
   "source": [
    "# an example of calculating semantic similarity between two sentences\n",
    "sentence1 = \"natural language understanding\"\n",
    "sentence2 = \"comprensión del lenguaje natural\"\n",
    "# encode sentences to get their embeddings\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "print(\"Sentence 1:\", sentence1)\n",
    "print(\"Sentence 2:\", sentence2)\n",
    "print(\"Similarity score:\", cosine_scores.item())\n",
    "\n",
    "\n",
    "# Retrieve top K most similar sentences from a corpus given a query sentence\n",
    "corpus = [\"I like Python because I can build AI applications\",\n",
    "          \"Me gusta Python porque puedo hacer análisis de datos\",\n",
    "          \"The cat sits on the ground\",\n",
    "         \"El gato camina por la acera.\"]\n",
    "# encode corpus to get corpus embeddings\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "sentence = \"I like Javascript because I can build web applications\"\n",
    "# encode sentence to get sentence embeddings\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "# top_k results to return\n",
    "top_k=2\n",
    "# compute similarity scores of the sentence with the corpus\n",
    "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
    "# Sort the results in decreasing order and get the first top_k\n",
    "top_results = np.argpartition(-cos_scores.cpu(), range(top_k))[0:top_k]\n",
    "print(\"\\nSentence:\", sentence)\n",
    "print(\"Top\", top_k, \"most similar sentences in corpus:\")\n",
    "for idx in top_results[0:top_k]:\n",
    "    print(corpus[idx], \"(Score: %.4f)\" % (cos_scores[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29321d43",
   "metadata": {},
   "source": [
    "### Visualize Multilingual Semantic Similarity\n",
    "With text embeddings in hand, we can take their dot-product to visualize how similar sentences are between languages. A darker color indicates the embeddings are semantically similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cfd62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:27.691248Z",
     "start_time": "2022-07-07T00:33:27.680630Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_similarity(embeddings_1, embeddings_2, labels_1, labels_2,\n",
    "                         plot_title,\n",
    "                         plot_width=1200, plot_height=600,\n",
    "                         xaxis_font_size='12pt', yaxis_font_size='12pt'):\n",
    "\n",
    "  assert len(embeddings_1) == len(labels_1)\n",
    "  assert len(embeddings_2) == len(labels_2)\n",
    "\n",
    "  # cosine based text similarity\n",
    "  sim = util.pytorch_cos_sim(embeddings_1, embeddings_2)\n",
    "\n",
    "  embeddings_1_col, embeddings_2_col, sim_col = [], [], []\n",
    "  for i in range(len(embeddings_1)):\n",
    "    for j in range(len(embeddings_2)):\n",
    "      embeddings_1_col.append(labels_1[i])\n",
    "      embeddings_2_col.append(labels_2[j])\n",
    "      sim_col.append(np.float(sim[i][j]))\n",
    "  df = pd.DataFrame(zip(embeddings_1_col, embeddings_2_col, sim_col),\n",
    "                    columns=['embeddings_1', 'embeddings_2', 'sim'])\n",
    "\n",
    "  mapper = bokeh.models.LinearColorMapper(\n",
    "      palette=[*reversed(bokeh.palettes.YlOrRd[9])], low=df.sim.min(),\n",
    "      high=df.sim.max())\n",
    "\n",
    "  p = bokeh.plotting.figure(title=plot_title, x_range=labels_1,\n",
    "                            x_axis_location=\"above\",\n",
    "                            y_range=[*reversed(labels_2)],\n",
    "                            plot_width=plot_width, plot_height=plot_height,\n",
    "                            tools=\"save\",toolbar_location='below', tooltips=[\n",
    "                                ('pair', '@embeddings_1 ||| @embeddings_2'),\n",
    "                                ('sim', '@sim')])\n",
    "  p.rect(x=\"embeddings_1\", y=\"embeddings_2\", width=1, height=1, source=df,\n",
    "         fill_color={'field': 'sim', 'transform': mapper}, line_color=None)\n",
    "\n",
    "  p.title.text_font_size = '12pt'\n",
    "  p.axis.axis_line_color = None\n",
    "  p.axis.major_tick_line_color = None\n",
    "  p.axis.major_label_standoff = 16\n",
    "  p.xaxis.major_label_text_font_size = xaxis_font_size\n",
    "  p.xaxis.major_label_orientation = 0.25 * np.pi\n",
    "  p.yaxis.major_label_text_font_size = yaxis_font_size\n",
    "  p.min_border_right = 300\n",
    "\n",
    "  bokeh.io.output_notebook()\n",
    "  bokeh.io.show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebe2f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:27.792295Z",
     "start_time": "2022-07-07T00:33:27.694251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/sig/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1032\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1032\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1032\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1032\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1032\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"d9de3a7b-b8eb-4fe9-9c0b-9489c90a130e\" data-root-id=\"1003\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"37cd3071-7cba-4f5b-b832-10d76ab2ab31\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"1014\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1019\"}],\"left\":[{\"id\":\"1017\"}],\"min_border_right\":300,\"renderers\":[{\"id\":\"1030\"}],\"title\":{\"id\":\"1004\"},\"toolbar\":{\"id\":\"1022\"},\"toolbar_location\":\"below\",\"width\":1200,\"x_range\":{\"id\":\"1006\"},\"x_scale\":{\"id\":\"1010\"},\"y_range\":{\"id\":\"1008\"},\"y_scale\":{\"id\":\"1012\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis_line_color\":null,\"coordinates\":null,\"formatter\":{\"id\":\"1038\"},\"group\":null,\"major_label_orientation\":0.7853981633974483,\"major_label_policy\":{\"id\":\"1039\"},\"major_label_standoff\":16,\"major_label_text_font_size\":\"12pt\",\"major_tick_line_color\":null,\"ticker\":{\"id\":\"1015\"}},\"id\":\"1014\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"high\":0.6258423328399658,\"low\":0.36385101079940796,\"palette\":[\"#ffffcc\",\"#ffeda0\",\"#fed976\",\"#feb24c\",\"#fd8d3c\",\"#fc4e2a\",\"#e31a1c\",\"#bd0026\",\"#800026\"]},\"id\":\"1002\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"1036\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{\"factors\":[\"dog\",\"Puppies are nice.\",\"I enjoy taking long walks along the beach with my dog.\"]},\"id\":\"1006\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1039\",\"type\":\"AllLabels\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"pair\",\"@embeddings_1 ||| @embeddings_2\"],[\"sim\",\"@sim\"]]},\"id\":\"1021\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis\":{\"id\":\"1014\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1035\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1038\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"factors\":[\"Disfruto de dar largos paseos por la playa con mi perro.\",\"Los cachorros son agradables.\",\"perro\"]},\"id\":\"1008\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"fill_color\":{\"field\":\"sim\",\"transform\":{\"id\":\"1002\"}},\"height\":{\"value\":1},\"line_color\":{\"value\":null},\"width\":{\"value\":1},\"x\":{\"field\":\"embeddings_1\"},\"y\":{\"field\":\"embeddings_2\"}},\"id\":\"1027\",\"type\":\"Rect\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"field\":\"sim\",\"transform\":{\"id\":\"1002\"}},\"hatch_alpha\":{\"value\":0.2},\"height\":{\"value\":1},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":null},\"width\":{\"value\":1},\"x\":{\"field\":\"embeddings_1\"},\"y\":{\"field\":\"embeddings_2\"}},\"id\":\"1029\",\"type\":\"Rect\"},{\"attributes\":{\"source\":{\"id\":\"1025\"}},\"id\":\"1031\",\"type\":\"CDSView\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1025\"},\"glyph\":{\"id\":\"1027\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1029\"},\"nonselection_glyph\":{\"id\":\"1028\"},\"view\":{\"id\":\"1031\"}},\"id\":\"1030\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_line_color\":null,\"coordinates\":null,\"formatter\":{\"id\":\"1035\"},\"group\":null,\"major_label_policy\":{\"id\":\"1036\"},\"major_label_standoff\":16,\"major_label_text_font_size\":\"12pt\",\"major_tick_line_color\":null,\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"}]},\"id\":\"1022\",\"type\":\"Toolbar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"sim\",\"transform\":{\"id\":\"1002\"}},\"hatch_alpha\":{\"value\":0.1},\"height\":{\"value\":1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":null},\"width\":{\"value\":1},\"x\":{\"field\":\"embeddings_1\"},\"y\":{\"field\":\"embeddings_2\"}},\"id\":\"1028\",\"type\":\"Rect\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"English-Spanish Similarity\",\"text_font_size\":\"12pt\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{\"data\":{\"embeddings_1\":[\"dog\",\"dog\",\"dog\",\"Puppies are nice.\",\"Puppies are nice.\",\"Puppies are nice.\",\"I enjoy taking long walks along the beach with my dog.\",\"I enjoy taking long walks along the beach with my dog.\",\"I enjoy taking long walks along the beach with my dog.\"],\"embeddings_2\":[\"perro\",\"Los cachorros son agradables.\",\"Disfruto de dar largos paseos por la playa con mi perro.\",\"perro\",\"Los cachorros son agradables.\",\"Disfruto de dar largos paseos por la playa con mi perro.\",\"perro\",\"Los cachorros son agradables.\",\"Disfruto de dar largos paseos por la playa con mi perro.\"],\"index\":[0,1,2,3,4,5,6,7,8],\"sim\":{\"__ndarray__\":\"AAAA4Pue4j8AAACgvIHcPwAAAAC8nNk/AAAAwIY54D8AAADgejfjPwAAAKDvxd0/AAAAwFVJ1z8AAABAF3fgPwAAAIDmBuQ/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[9]}},\"selected\":{\"id\":\"1041\"},\"selection_policy\":{\"id\":\"1040\"}},\"id\":\"1025\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"37cd3071-7cba-4f5b-b832-10d76ab2ab31\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"d9de3a7b-b8eb-4fe9-9c0b-9489c90a130e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some texts of different lengths in different languages.\n",
    "english_sentences = ['dog', 'Puppies are nice.', 'I enjoy taking long walks along the beach with my dog.']\n",
    "spanish_sentences = ['perro', 'Los cachorros son agradables.', 'Disfruto de dar largos paseos por la playa con mi perro.']\n",
    "\n",
    "# Compute embeddings.\n",
    "en_result = embed_text(english_sentences)\n",
    "es_result = embed_text(spanish_sentences)\n",
    "\n",
    "# visualize semantic similarity\n",
    "visualize_similarity(en_result, es_result, english_sentences, spanish_sentences, 'English-Spanish Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176f514",
   "metadata": {},
   "source": [
    "## Build a simple cross-lingual document retrieval engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f41075",
   "metadata": {},
   "source": [
    "### Download Data to Index\n",
    "Download news sentences in multiples languages (English and Spanish) from the [News Commentary Corpus](http://opus.nlpl.eu/News-Commentary-v11.php) [1].\n",
    "\n",
    "To speed up the demo, we limit to 1000 sentences per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec44292c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:27.800817Z",
     "start_time": "2022-07-07T00:33:27.793735Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_files(corpus_metadata):\n",
    "  language_to_sentences = {}\n",
    "  language_to_news_path = {}\n",
    "  for language_code, zip_file, news_file, language_name in corpus_metadata:\n",
    "    zip_path = tf.keras.utils.get_file(\n",
    "        fname=zip_file,\n",
    "        origin='http://opus.nlpl.eu/download.php?f=News-Commentary/v11/moses/' + zip_file,\n",
    "        extract=True)\n",
    "    news_path = os.path.join(os.path.dirname(zip_path), news_file)\n",
    "    language_to_sentences[language_code] = pd.read_csv(news_path, sep='\\t', header=None)[0][:1000]\n",
    "    language_to_news_path[language_code] = news_path\n",
    "\n",
    "    print('{:,} {} sentences'.format(len(language_to_sentences[language_code]), language_name))\n",
    "  return language_to_sentences, language_to_news_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1a7230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:29.908043Z",
     "start_time": "2022-07-07T00:33:27.802345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 English sentences\n",
      "1,000 Spanish sentences\n"
     ]
    }
   ],
   "source": [
    "corpus_metadata = [\n",
    "    ('en', 'en-es.txt.zip', 'News-Commentary.en-es.en', 'English'),\n",
    "    ('es', 'en-es.txt.zip', 'News-Commentary.en-es.es', 'Spanish'),\n",
    "]\n",
    "language_to_sentences, language_to_news_path = download_files(corpus_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918390df",
   "metadata": {},
   "source": [
    "### Get document embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f64e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:56.536124Z",
     "start_time": "2022-07-07T00:33:29.909526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing English embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                           | 0/1000 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Spanish embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                           | 0/1000 [00:13<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "language_to_embeddings = {}\n",
    "for language_code, zip_file, news_file, language_name in corpus_metadata:\n",
    "  print('\\nComputing {} embeddings'.format(language_name))\n",
    "  with tqdm(total=len(language_to_sentences[language_code])) as pbar:\n",
    "    df = pd.read_csv(language_to_news_path[language_code],\n",
    "                             sep='\\t',header=None).head(sample_size)\n",
    "    for i in range(len(df)):\n",
    "      language_to_embeddings.setdefault(language_code, []).append(embed_text(df[0][i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a986f7",
   "metadata": {},
   "source": [
    "### Building an index of semantic vectors\n",
    "\n",
    "Use the [SimpleNeighbors](https://pypi.org/project/simpleneighbors/) library---which is a wrapper for the [Annoy](https://github.com/spotify/annoy) library---to efficiently look up results from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db72293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:57.094503Z",
     "start_time": "2022-07-07T00:33:56.538030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding English embeddings to index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5286.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English index with 40 trees...\n",
      "\n",
      "Adding Spanish embeddings to index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5764.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Spanish index with 40 trees...\n",
      "CPU times: user 482 ms, sys: 63.9 ms, total: 546 ms\n",
      "Wall time: 552 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_index_trees = 40\n",
    "language_name_to_index = {}\n",
    "embedding_dimensions = len(list(language_to_embeddings.values())[0][0])\n",
    "for language_code, zip_file, news_file, language_name in corpus_metadata:\n",
    "  print('\\nAdding {} embeddings to index'.format(language_name))\n",
    "  index = SimpleNeighbors(embedding_dimensions, metric='cosine')\n",
    "\n",
    "  for i in trange(len(language_to_sentences[language_code])):\n",
    "    index.add_one(language_to_sentences[language_code][i], language_to_embeddings[language_code][i])\n",
    "\n",
    "  print('Building {} index with {} trees...'.format(language_name, num_index_trees))\n",
    "  index.build(n=num_index_trees)\n",
    "  language_name_to_index[language_name] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b693fc47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:57.586809Z",
     "start_time": "2022-07-07T00:33:57.095960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mixed-language index\n",
      "Adding English embeddings to mixed-language index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5735.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Spanish embeddings to mixed-language index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6093.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building mixed-language index with 60 trees...\n",
      "CPU times: user 449 ms, sys: 47.6 ms, total: 496 ms\n",
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_index_trees = 60\n",
    "print('Computing mixed-language index')\n",
    "combined_index = SimpleNeighbors(embedding_dimensions, metric='cosine')\n",
    "for language_code, zip_file, news_file, language_name in corpus_metadata:\n",
    "  print('Adding {} embeddings to mixed-language index'.format(language_name))\n",
    "  for i in trange(len(language_to_sentences[language_code])):\n",
    "    annotated_sentence = '({}) {}'.format(language_name, language_to_sentences[language_code][i])\n",
    "    combined_index.add_one(annotated_sentence, language_to_embeddings[language_code][i])\n",
    "\n",
    "print('Building mixed-language index with {} trees...'.format(num_index_trees))\n",
    "combined_index.build(n=num_index_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c70d30",
   "metadata": {},
   "source": [
    "### Validate the document retrieval pipeline\n",
    "\n",
    "1.   Retrieve sentences from the corpus that are semantically similar to the given query.\n",
    "2.   Cross-lingual: Issue queries in a distinct language than the indexed corpus\n",
    "3.   Mixed-corpus: Issue queries in one language and retrieve similar documents from multiple languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3eda5",
   "metadata": {},
   "source": [
    "#### Cross-lingual\n",
    "\n",
    "Issue queries in a distinct language than the indexed corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373e4ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:57.748505Z",
     "start_time": "2022-07-07T00:33:57.588290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish sentences similar to: \"The stock market fell four points.\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Los precios del oro incluso alcanzaron recientemente un récord de 1.300 dólares.',\n",
       " 'Pero el acuerdo alcanzado tiene tres grandes defectos.',\n",
       " 'Las grandes empresas deben aceptar la responsabilidad por sus acciones.',\n",
       " 'Si se extendiera la política a empresas de terceros países, esto tendría un fuerte impacto liberalizador.',\n",
       " 'Después me distraje durante aproximadamente 40 años.',\n",
       " 'Ese aumento de los activos permitirá, a su vez, a los mercados crediticios locales, como, por ejemplo, el de la microfinanciación comenzar a funcionar.',\n",
       " 'Desde entonces, el índice ha trepado por encima de 10.000.',\n",
       " 'También existe el un creciente peligro del terrorismo interno.',\n",
       " 'Los recursos de inteligencia se han redireccionado.',\n",
       " 'Desde que aparecieron sus artículos, el precio del oro aumentó aún más.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query = 'The stock market fell four points.'\n",
    "index_language = 'Spanish'  #@param [\"English\", \"Spanish\"]\n",
    "num_results = 10  #@param {type:\"slider\", min:0, max:100, step:10}\n",
    "\n",
    "query_embedding = embed_text(sample_query)\n",
    "search_results = language_name_to_index[index_language].nearest(query_embedding, n=num_results)\n",
    "\n",
    "print('{} sentences similar to: \"{}\"\\n'.format(index_language, sample_query))\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee51d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:57.964878Z",
     "start_time": "2022-07-07T00:33:57.751267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentences similar to: \"Desde entonces, el índice ha trepado por encima de 10.000.\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Since then, the index has climbed above 10,000.',\n",
       " 'His ratings have dipped below 50% for the first time.',\n",
       " 'Since their articles appeared, the price of gold has moved up still further.',\n",
       " 'But where will increased competitiveness come from?',\n",
       " 'Gold prices even hit a record-high $1,300 recently.',\n",
       " 'At $1,300, today’s price is probably more than double very long-term, inflation-adjusted, average gold prices.',\n",
       " 'After adjusting for inflation, today’s price is nowhere near the all-time high of January 1980.',\n",
       " 'International cooperation has increased markedly, in part because governments that cannot agree on many things can agree on the need to cooperate in this area.',\n",
       " 'Last December, many gold bugs were arguing that the price was inevitably headed for $2,000.',\n",
       " 'Of course, there are obvious differences between 1989 and now.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query = 'Desde entonces, el índice ha trepado por encima de 10.000.'\n",
    "index_language = 'English'  #@param [\"English\", \"Spanish\"]\n",
    "num_results = 10  #@param {type:\"slider\", min:0, max:100, step:10}\n",
    "\n",
    "query_embedding = embed_text(sample_query)\n",
    "search_results = language_name_to_index[index_language].nearest(query_embedding, n=num_results)\n",
    "\n",
    "print('{} sentences similar to: \"{}\"\\n'.format(index_language, sample_query))\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15a2d4",
   "metadata": {},
   "source": [
    "#### Mixed-corpus capabilities\n",
    "\n",
    "Issue a query in English and the results will come from the any of the indexed languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c166651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T00:33:58.235009Z",
     "start_time": "2022-07-07T00:33:57.968006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilingual sentences similar to: \"The stock market fell four points.\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(English) Since their articles appeared, the price of gold has moved up still further.',\n",
       " '(English) Intelligence assets have been redirected.',\n",
       " '(English) But, globally, our innovation system needs much bigger changes.',\n",
       " '(English) But neither improved competitiveness, nor reduction of total debt, can be achieved overnight.',\n",
       " '(English) As legions of new consumers gain purchasing power, demand inevitably rises, driving up the price of scarce commodities.',\n",
       " '(English) Other IMF accounting practices, including how the capital expenditures of government-owned enterprises are treated, are also causing outrage. If a state owned enterprise',\n",
       " '(Spanish) Los precios del oro incluso alcanzaron recientemente un récord de 1.300 dólares.',\n",
       " '(English) His ratings have dipped below 50% for the first time.',\n",
       " '(English) With serious management of the new funds, food production in Africa will soar.',\n",
       " '(Spanish) Pero el acuerdo alcanzado tiene tres grandes defectos.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'The stock market fell four points.'  #@param {type:\"string\"}\n",
    "num_results = 10  #@param {type:\"slider\", min:0, max:100, step:10}\n",
    "\n",
    "query_embedding = embed_text(query)\n",
    "search_results = combined_index.nearest(query_embedding, n=num_results)\n",
    "\n",
    "print('Multilingual sentences similar to: \"{}\"\\n'.format(query))\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb063ff7",
   "metadata": {},
   "source": [
    "[1] J. Tiedemann, 2012, [Parallel Data, Tools and Interfaces in OPUS](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf). In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
